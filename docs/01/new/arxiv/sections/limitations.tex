\section{Limitations}

The framework applies to systems whose outputs can be reduced to discrete identities via a declared equivalence policy. Continuous outputs such as probability distributions and regression surfaces are out of scope unless such a reduction is explicitly defined. The choice of equivalence policy directly determines what counts as ``the same outcome,'' and different policies applied to the same raw output will in general produce different decision maps.

All results assume a frozen snapshot and a fixed engine. Any change to the input data, model parameters, or execution logic constitutes a new analytical context. The framework does not track how decision maps evolve across snapshot or engine versions; each combination requires a separate analysis.

The reported sweeps cover two representation parameters, neighbor weight at values 0.5 and 1.0 and second-order weight at values 0.25 and 0.5, applied to a single graph snapshot with a single origin-destination pair. The representation space is sampled at four points total. Unobserved regions of representation space remain unconstrained, and persistence regions and boundaries identified here may not generalize to finer parameter grids, different origin-destination pairs, or different graph topologies.

The empirical demonstration uses graph routing. The framework is designed to be domain-agnostic, but it has not been validated on classification, resource allocation, or other pipeline types. Applying the framework to a new domain requires defining an appropriate equivalence policy, which involves domain-specific judgment about what constitutes ``the same outcome.''

Observing that a boundary exists between two parameter values does not explain why it exists. The framework is diagnostic, not explanatory. It identifies where decision identity changes but does not attribute the change to any specific mechanism within the engine or the representation construction.

The current implementation uses SQLite and has been tested with single-digit representation families. Scaling to large parameter grids of hundreds or thousands of representations would require evaluation of storage, query performance, and sweep orchestration, none of which has been performed.
